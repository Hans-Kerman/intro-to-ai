
### 项目 5：机器学习
**截止日期：**2025年12月1日，星期一，晚上11:59（太平洋时间）

---

[**图片描述：** 一张手写数字分类器的可视化结果图。图中显示了模型在第0.25个周期（共5个周期）时的测试准确率为92.55%。每一行代表一个数字（0-9），并展示了模型对多个手写样本的正确标签概率预测。]

---

### 目录

* 简介
* 安装
 * 安装 Pytorch
 * 可能的 Numpy Bug 提示
* Pytorch 提供的函数 (第一部分)
* 问题 1 (5分): 感知机
* 神经网络技巧
 * 构建神经网络
 * 批处理 (Batching)
 * 随机性
 * 设计网络架构
* 示例：线性回归
* 问题 2 (5分): 非线性回归
* 问题 3 (5分): 数字分类
* 问题 4 (5分): 语言识别
 * 批处理
 * 设计技巧
 * 你的任务
* 问题 5 (3分): 卷积神经网络
* 问题 6 (2分): 注意力机制 (Attention)
* 问题 7 (0分，但很有趣): 字符级GPT (character-GPT)
* 提交

---

### 简介

本项目将作为机器学习的入门；你将构建一个神经网络来分类数字，以及完成更多任务！你可以从这里下载项目所需文件的 zip 压缩包：[zip archive](https://inst.eecs.berkeley.edu/~cs188/fa25/projects/proj5/proj5.zip)。

**你需要编辑的文件：**

| 文件名 | 描述 |
| :--- | :--- |
| `models.py` | 用于各种应用的感知机和神经网络模型。 |
| `losses.py` | 为你的模型设计的损失函数。 |
| `train.py` | 为你的模型设计的训练循环。 |

**你可以忽略的支持文件：**

| 文件名 | 描述 |
| :--- | :--- |
| `autograder.py` | 项目自动评分器。 |
| `backend.py` | 各种机器学习任务的后端代码。 |
| `data` | 用于数字分类和语言识别的数据集。 |

**需要编辑和提交的文件：** 在整个任务中，你将填充 `models.py`、`train.py`、`losses.py` 的部分内容。完成作业后，你需要将这些文件提交到 Gradescope（例如，你可以上传文件夹中所有的 `.py` 文件）。请不要更改此发行版中的其他文件。

**评分：** 你的代码将由自动评分器进行技术正确性评估。请不要更改代码中任何已提供函数或类的名称，否则会严重影响自动评分器。然而，你实现的正确性——而非自动评分器的判断——将是你得分的最终依据。如有必要，我们会单独审查和评分作业，以确保你获得应得的分数。

**学术诚信：** 我们会检查你的代码与课堂上其他提交的代码是否存在逻辑上的冗余。如果你复制他人的代码并稍作修改后提交，我们是会知道的。这些查重检测器很难被欺骗，所以请不要尝试。我们相信大家只会提交自己的作品；请不要让我们失望。如果你这样做，我们将采取最严厉的措施。

**寻求帮助：** 你不是一个人在战斗！如果你在某些地方卡住了，请联系课程团队寻求帮助。办公时间（Office hours）、答疑课（section）和讨论论坛都是为你提供支持的；请善加利用。如果你无法参加我们的办公时间，请告诉我们，我们会安排更多时间。我们希望这些项目是有益且具有指导性的，而不是令人沮丧和士气低落的。但是，除非你主动提问，否则我们不知道何时以及如何帮助你。

**讨论：** 请注意不要发布剧透内容。

---

### 安装

如果以下命令能够运行，并且你看到下面弹出的窗口中有一条线段在圆圈内旋转，你可以跳到 Pytorch 的安装步骤。你应该使用 conda 环境来完成这个项目，因为 conda 自带了我们需要的库。

```bash
python autograder.py --check-dependencies
```
[**图片描述：** 一个标题为 "Figure 1" 的 matplotlib 窗口，坐标轴范围从-1.0到1.0，其中绘制了一条从左下到右上的直线。]

对于这个项目，你需要安装以下三个库：
* **numpy**：提供对快速、大型多维数组的支持。
* **matplotlib**：一个2D绘图库。
* **pytorch**：一个用于创建神经网络的库。

如果你有 conda 环境，你可以通过在命令行运行以下命令来安装 numpy 和 matplotlib：
```bash
conda activate [你的环境名称]
pip install numpy
pip install matplotlib
```
你不会直接使用这些库，但运行提供的代码和自动评分器需要它们。

如果你的设置不同，你可以参考 numpy 和 matplotlib 的安装说明。你可以使用 `pip` 或 `conda` 来安装这些包；`pip` 在 conda 环境内外都可以工作。

安装后，请再次尝试依赖检查。

#### 安装 Pytorch
接下来，如果你还没有安装 pytorch，你需要安装它。首先激活你的 conda 环境：
```bash
conda activate [你的环境名称]
```
然后你可以按照这里的说明：[Pytorch 官网](https://pytorch.org/get-started/locally/)，使用 Conda 或 Pip 下载最新版本的 Pytorch。如果你以前没有用过 Pytorch，请使用 CPU 版本。CPU 版本的 Pytorch 最不容易引起任何 bug 或复杂问题。

> **⚠️ 可能的 Numpy Bug**
> 如果你遇到任何 numpy 相关的错误，请尝试将 numpy 版本降级到 `1.24.3` 或任何低于 `2.0.0` 的版本。

---

### Pytorch 提供的函数 (第一部分)

* `tensor()`: 张量（Tensors）是 pytorch 中的主要数据结构。它们的工作方式与 Numpy 数组非常相似，你可以对它们进行加法和乘法运算。任何时候当你使用 pytorch 函数或将输入送入神经网络时，都应该确保你的输入是张量形式。你可以像这样将一个 python 列表转换为张量：`tensor(data)`，其中 `data` 是你的n维列表。
* `ones(dims...)`: 创建一个维度为 `dims`、所有元素都填充为1的张量，例如 `ones(1,2,3)` 会得到一个 1x2x3 的张量，其中所有元素都是1。
* `relu(input)`: pytorch 中的 relu 激活函数是这样调用的：`relu(input)`。它接受一个输入，并返回 `max(input, 0)`。
* `Linear`: 使用这个类来实现一个线性层。一个线性层会计算你的权重向量和输入的点积。你必须在你的 `__init__` 函数中像这样初始化它：`self.layer = Linear(输入向量长度, 输出向量长度)`，并在运行你的模型时这样调用它：`self.layer(input)`。当你这样定义一个线性层时，Pytorch 会自动创建权重并在训练期间更新它们。
* `movedim(input_vector, initial_dimension_position, final_dimension_position)`: 这个函数接受一个矩阵，并将 `initial_dimension_position`（以整数形式传入）与 `final_dimension_position` 的维度进行交换。这在问题4中会很有用。
* `cross_entropy(prediction, target)`: 这个函数应该是你用于任何分类任务（问题3-5）的损失函数。你的预测离目标越远，这个函数返回的值就越高。
* `mse_loss(prediction, target)`: 这个函数应该是你用于任何回归任务（问题2）的损失函数。它的使用方式与 `cross_entropy` 相同。

在 pytorch 版本中，所有数据都将以 pytorch `Dataset` 对象的形式提供给你，你将把它转换成 pytorch `DataLoader` 以便轻松创建批次大小。
```python
>>> data = DataLoader(training_dataset, batch_size = 64)
>>> for batch in data:
>>>     # 训练代码在这里
```
对于所有这些问题，`DataLoader` 返回的每个批次都将是一个字典，形式为： `{'x': features, ‘label’: label}`，其中 `label` 是我们希望根据 `features` 预测的值。

---

### 问题 1 (5分): 感知机

在开始这部分之前，请确保你已经安装了 `pytorch`、`numpy` 和 `matplotlib`！

在这一部分，你将实现一个二元感知机。你的任务是完成 `models.py` 中的 `PerceptronModel` 类和 `train.py` 中的 `train_perceptron` 的实现。

对于感知机，输出标签将是 `1` 或 `-1`，这意味着来自数据集的数据点 `(x, y)` 将有一个 `y`，它是一个 `torch.Tensor`，其条目为 `1` 或 `-1`。

**你的任务是：**
* 填写 `init(self, dimensions)` 函数。这应该在 `PerceptronModel` 中初始化权重参数。注意，在这里，你应该确保你的权重变量被保存为一个维度为 `1 x dimensions` 的 `Parameter()` 对象。这样做是为了让我们的自动评分器以及 pytorch 将你的权重识别为你模型的一个参数。
* 实现 `forward(self, x)` 方法。这应该计算存储的权重向量和给定输入的点积，返回一个 `Tensor` 对象。
* 实现 `get_prediction(self, x)`，如果点积为非负数，则应返回 `1`，否则返回 `-1`。
* 在 `train.py` 中编写 `train_perceptron` 方法。这应该重复地遍历数据集，并对被错误分类的样本进行更新。当完整地遍历一次数据集而没有任何错误时，训练准确率达到100%，训练可以终止。注意，你可以通过 `model(data)` 而不是 `model.forward(data)` 来调用模型的 `forward` 方法。
* 幸运的是，Pytorch 使得在张量上运行操作变得容易。如果你想通过某个张量 `direction` 和一个常数 `magnitude` 来更新你的权重，你可以这样做：`self.w += direction * magnitude`

对于这个问题以及所有剩下的问题，`DataLoader` 返回的每个批次都将是一个字典，形式为：`{'x': features, 'label': label}`，其中 `label` 是我们希望根据 `features` 预测的值。

要测试你的实现，请运行自动评分器：
```bash
python autograder.py -q q1
```
要无图形界面运行：
```bash
python autograder.py -q q1 --no-graphics
```
**注意：** 对于一个正确的实现，无图形界面的自动评分器最多应该花费30秒左右的时间。如果你的自动评分器运行时间过长，你的代码可能有一个 bug。

---

### 神经网络技巧

在项目的其余部分，你将实现以下模型：
* **Q2: 非线性回归**
* **Q3: 手写数字分类**
* **Q4: 语言识别**
* **Q5: 使用CNN进行手写数字分类**
* **Q6: 注意力机制 (Attention)**

#### 构建神经网络
在项目的应用部分，你将使用Pytorch来创建神经网络，以解决各种机器学习问题。一个简单的神经网络有线性层，其中每个线性层执行一个线性操作（就像感知机一样）。线性层之间由一个**非线性**部分隔，这允许网络逼近通用函数。我们将使用ReLU操作作为我们的非线性部分，定义为 `relu(x) = max(x, 0)`。例如，一个用于将输入行向量 **x** 映射到输出向量 **f(x)** 的简单单隐藏层/双线性层神经网络将由以下函数给出：

**f(x) = relu(x · W₁ + b₁) · W₂ + b₂**

在这里，我们有参数矩阵 **W₁** 和 **W₂** 以及参数向量 **b₁** 和 **b₂** 在梯度下降期间进行学习。**W₁** 将是一个 *i × h* 的矩阵，其中 *i* 是我们输入向量 **x** 的维度，*h* 是隐藏层的大小。**b₁** 将是一个大小为 *h* 的向量。我们可以自由选择隐藏层的任何值（我们只需要确保其他矩阵和向量的维度一致以便我们能够执行操作）。使用更大的隐藏层大小通常会使网络更强大（能够拟合更多的训练数据），但也会使网络更难训练（因为它为我们需要学习的所有矩阵和向量增加了更多的参数），或者可能导致对训练数据的过拟合。

我们也可以通过添加更多的层来创建更深的网络，例如一个三线性层的网络：
**ŷ = f(x) = relu(relu(x · W₁ + b₁) · W₂ + b₂) · W₃ + b₃**

或者，我们可以分解上述内容并明确指出2个隐藏层：
**h₁ = f₁(x) = relu(x · W₁ + b₁)
h₂ = f₂(h₁) = relu(h₁ · W₂ + b₂)
ŷ = f₃(h₂) = h₂ · W₃ + b₃**

请注意，我们最后没有使用 `relu`，因为我们希望能够输出负数，而且 `relu` 的初衷是进行非线性变换，将输出作为某个非线性中间体的仿射线性变换是非常合理的。

#### 批处理 (Batching)
为了效率，你需要一次性处理整批数据，而不是一次处理一个样本。这意味着，你将面对的不是一个大小为 *i* 的单个输入行向量 **x**，而是一个由 *b* 个输入组成的批次，表示为一个 *b × i* 的矩阵 **X**。我们提供了一个线性回归的例子，来演示如何在批处理设置中实现一个线性层。

#### 随机性
你的神经网络参数将被随机初始化，并且在某些任务中，数据将以打乱的顺序呈现。由于这种随机性，即使有强大的架构，你仍有可能偶尔失败一些任务——这就是局部最优的问题！这种情况应该很少发生——如果在测试你的代码时，你连续两次在同一个问题上失败了自动评分器，你应该探索其他的架构。

#### 设计网络架构
设计神经网络可能需要一些反复试验。这里有一些技巧可以帮助你：
* **系统化。** 记录你尝试过的每一种架构，它们的超参数（层大小、学习率等）是什么，以及最终的性能如何。当你尝试更多东西时，你可以开始看到关于哪些参数重要的模式。如果你在代码中发现了一个bug，一定要划掉那些因bug而无效的旧结果。
* **从一个浅层网络开始** (只有一个隐藏层，即一个非线性)。更深的网络有指数级更多的超参数组合，即使弄错一个也可能毁掉你的性能。使用小网络找到一个好的学习率和层大小；之后你可以考虑添加更多类似大小的层。
* **如果你的学习率是错误的，你其他的超参数选择都无关紧要。** 你可以从一篇研究论文中拿一个最先进的模型，然后改变学习率，使其表现不比随机猜测好。学习率太低会导致模型学习太慢，学习率太高可能导致损失发散到无穷大。开始时尝试不同的学习率，同时观察损失随时间如何减少。
* **更小的批次需要更低的学习率。** 在试验不同批次大小时，要注意最佳学习率可能会因批次大小而异。
* **避免使网络太宽** (隐藏层大小太大)。如果你不断加宽网络，准确率会逐渐下降，计算时间会以层大小的平方级增加——你很可能因为速度太慢而放弃，远在准确率下降太多之前。该项目所有部分的完整自动评分器在标准解决方案下大约需要12分钟运行；如果你的代码花费的时间长得多，你应该检查其效率。
* 如果你的模型返回 `Infinity` 或 `NaN`，你的学习率对于当前架构来说可能太高了。
* **推荐的超参数值：**
 * 隐藏层大小：介于 100 和 500 之间。
 * 批次大小：介于 1 和 128 之间。对于Q2和Q3，我们要求数据集的总大小能被批次大小整除。
 * 学习率：介于 0.0001 和 0.01 之间。
 * 隐藏层数量：介于 1 和 3 之间（在这里从小处着手尤其重要）。

---

### 示例：线性回归

作为神经网络框架如何工作的一个例子，让我们拟合一条直线到一组数据点。我们将从使用函数 `y = 7x₀ + 8x₁ + 3` 构建的四个训练数据点开始。以批处理形式，我们的数据是：
```
      [0 0]         [ 3]
      [0 1]         [11]
X =   [1 0]     Y = [10]
      [1 1]         [18]
```
假设数据以张量 `S` 的形式提供给我们。
```python
>>> x
torch.Tensor([[0,0],[0,1],[1,0],[1,1]])
>>> y
torch.Tensor([[3],[11],[10],[18]])
```
让我们构建并训练一个形式为 **f(x) = x₀ · m₀ + x₁ · m₁ + b** 的模型。如果做得正确，我们应该能学到 `m₀ = 7`，`m₁ = 8`，以及 `b = 3`。

首先，我们创建可训练的参数。以矩阵形式，它们是：
```
      [m₀]
M =   [m₁]      B =   [b]
```
这对应于以下代码：
```python
m = Tensor(2, 1)
b = Tensor(1, 1)
```
需要记住的一个小细节是，除非你用数据初始化张量，否则张量会用全0的值进行初始化。因此，打印它们会得到：
```python
>>> m
torch.Tensor([[0],[0]])
>>> b
torch.Tensor([[0]])
```
接下来，我们计算模型对 `y` 的预测。你必须在你的 `__init__()` 函数中定义一个线性层，如上面 `Linear` 的定义中所述：

`predicted_y = self.Linear_Layer(x)`

我们的目标是让预测的y值与提供的数据匹配。在线性回归中，我们通过最小化平方损失来做到这一点：
![公式 L = ...](https://latex.codecogs.com/svg.image?L%20%3D%20%5Cfrac%7B1%7D%7B2N%7D%20%5Csum_%7B(x%2Cy)%7D%20(y%20-%20f(x))^2)

我们计算我们的损失值：
`loss = mse_loss(predicted_y, y)`

最后，在定义了你的神经网络之后，为了训练你的网络，你首先需要初始化一个优化器。Pytorch内置了几种，但对于这个项目，请使用：`optim.Adam(self.parameters(), lr=lr)`，其中 `lr` 是你的学习率。一旦你定义了你的优化器，你必须在每次迭代中做以下事情来更新你的权重：
* 用 `optimizer.zero_grad()` 重置由 pytorch 计算的梯度
* 用 `predicted_y = model(x)` 获取你的模型预测
* 通过调用相关的损失函数计算你的损失张量，例如 `regression_loss(predicted_y, y)`
* 使用 `loss.backward()` 计算你的梯度，其中 `loss` 是由`get_loss`返回的你的损失张量
* 最后，通过调用 `optimizer.step()` 更新你的权重

你可以查看 [Pytorch 官方文档](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) 中关于如何使用 Pytorch 优化器的例子。

---

### 问题 2 (5分): 非线性回归

对于这个问题，你将训练一个神经网络来逼近在 `[−2π, 2π]` 区间上的 `sin(x)` 函数。

你需要完成 `models.py` 中的 `RegressionModel` 类，`train.py` 中的 `train_regression` 方法，以及 `losses.py` 中的 `regression_loss` 方法的实现。对于这个问题，一个相对简单的架构应该就足够了（参见神经网络技巧获取架构提示）。使用 `mse_loss` 作为你的损失函数。

**你的任务是：**
* 实现 `RegressionModel.__init__`，并进行任何需要的初始化。
* 实现 `RegressionModel.forward` 以返回一个 `batch_size x 1` 的节点，代表你模型的预测。
* 实现 `regression_loss` 以返回给定预测输出和目标输出的损失。
* 实现 `train_regression`，它应该使用基于梯度的更新来训练你的模型。

这个任务只有一个数据集分割（即，只有训练数据，没有验证数据或测试集）。如果你的实现能够在数据集中所有样本上平均获得0.02或更好的损失，你将获得满分。你可以使用训练损失来决定何时停止训练。注意，模型应该需要几分钟来训练。
```bash
python autograder.py -q q2
```

---

### 问题 3 (5分): 数字分类

对于这个问题，你将训练一个网络来分类来自 MNIST 数据集的手写数字。

每个数字的大小是 28x28 像素，其值存储在一个784维的浮点数向量中。我们提供的每个输出都是一个10维的向量，除了在对应数字正确类别的那个位置为1外，其他位置都为0。

完成 `models.py` 中 `DigitClassificationModel` 类、`train.py` 中 `train_digitclassifier` 方法以及 `losses.py` 中 `digitclassifier_loss` 的实现。`DigitClassificationModel.forward()` 的返回值应该是一个`batch_size x 10` 的节点，其中包含分数，分数越高表示数字属于特定类别（0-9）的概率越大。你应该使用 `cross_entropy`作为你的损失函数。不要在网络的最后一个线性层放置ReLU激活。

对于这个问题和Q4，除了训练数据外，还有验证数据和测试集。你可以使用 `dataset.get_validation_accuracy()` 来为你的模型计算验证准确率，这在决定是否停止训练时很有用。测试集将由自动评分器使用。

要获得这个问题分数，你的模型应该在测试集上达到至少97%的准确率。作为参考，我们的标准实现在训练约5个周期后，在验证数据上持续达到98%的准确率。请注意，测试是在测试准确率上对你进行评分，而你只能访问验证准确率，所以如果你的验证准确率达到了97%的阈值，但你的测试准确率没有达到，你可能仍然会测试失败。因此，设定一个稍高的停止阈值，比如97.5%或98%，可能会有帮助。

要测试你的实现，请运行自动评分器：
```bash
python autograder.py -q q3
```

---

### 问题 4 (5分): 语言识别

语言识别是这样一个任务：给定一段文本，判断出该文本是用什么语言写的。例如，你的浏览器可能能够检测到你访问了一个外语页面，并为你提供翻译。这里有一个来自Chrome的例子（它使用神经网络来实现这个功能）：

[**图片描述：** Chrome浏览器弹窗，提示“此页面是西班牙语”，并询问“您想翻译它吗？”]

在这个项目中，我们将构建一个小型的神经网络模型，一次识别一个单词的语言。我们的数据集包含五种语言的单词，如下表所示：

| 单词 | 语言 |
| :--- | :--- |
| discussed | English |
| eternidad | Spanish |
| itseänne | Finnish |
| paleis | Dutch |
| mieszkać | Polish |

不同的单词由不同数量的字母组成，所以我们的模型需要一个能够处理可变长度输入的架构。与之前的问题中单个输入 **x** 不同，我们将为单词中的每个字符提供一个单独的输入：**x₀, x₁, ..., xₗ₋₁**，其中L是单词的长度。

我们将从应用一个网络 `f_initial` 开始，这就像之前问题中的网络一样。它接受其输入 `x₀` 并计算一个维度为 `d` 的输出向量 `h₁`：
**h₁ = f_initial(x₀)**

接下来，我们将前一步的输出与单词中的下一个字母结合起来，生成单词前两个字母的向量摘要。为此，我们将应用一个子网络，它接受一个字母并输出一个隐藏状态，但现在也依赖于前一个隐藏状态 `h₁`。我们把这个子网络记为 `f`。
**h₂ = f(h₁, x₁)**

这个模式对输入单词中的所有字母继续进行，其中每一步的隐藏状态总结了网络到目前为止处理过的所有字母：
**h₃ = f(h₂, x₂)**
...

在这些计算中，函数 `f(., .)` 是同一个神经网络片段，并使用相同的可训练参数；`f_initial` 也将与 `f(., .)` 共享一些相同的参数。通过这种方式，处理不同长度的单词时使用的参数都是共享的。你可以使用一个遍历提供的输入 `xs` 的 `for` 循环来实现这一点，其中循环的每次迭代计算 `f_initial` 或 `f`。

上面描述的技术被称为**循环神经网络（RNN）**。RNN的示意图如下所示：

[**图片描述：** 一个循环神经网络（RNN）处理单词 "cat" 的示意图。输入 'c' (x₀) 进入 `f_initial` 模块生成 `h₁`。然后 `h₁` 和输入 'a' (x₁) 一起进入 `f` 模块生成 `h₂`。最后 `h₂` 和输入 't' (x₂) 一起进入 `f` 模块生成最终的隐藏状态 `h₃`。]

在这里，一个RNN被用来将单词"cat"编码成一个固定大小的向量 `h₃`。

在RNN处理完输入的全部长度后，它已将任意长度的输入单词编码成一个固定大小的向量 `hₗ`，其中L是单词的长度。这个输入单词的向量摘要现在可以被送入额外的输出转换层，以生成该单词语言身份的分类分数。

#### 批处理
尽管上述方程是针对单个单词的，但在实践中，你必须使用一批单词来提高效率。为了简单起见，我们项目中的代码确保了单个批次内的所有单词都具有相同的长度。在批处理形式中，一个隐藏状态 `hᵢ`被替换为维度为 `batch_size x d` 的矩阵 `Hᵢ`。

#### 设计技巧
循环函数 `f(·, ·)` 的设计是这个任务的主要挑战。这里有一些技巧：
* 输入字符是独热编码（one-hot encoded）的，维度为 `self.num_chars`，即一个在索引0处为1的向量代表字母 `a`。
* 从一个你选择的类似于之前问题的架构 `f_initial(x)` 开始，只要它至少有一个非线性。
* 你应该使用以下方法，在给定 `f_initial(x)` 的情况下构造 `f(·, ·)`。`f_initial` 的第一个转换层将通过将向量 `x₀` 乘以某个权重矩阵 `Wₓ` 开始，产生 `z₀ = x₀ · Wₓ`。对于后续的字母，你应该用 `zᵢ = xᵢ · Wₓ + hᵢ · W_hidden` 来替换这个计算，使用加法操作。换句话说，你应该用 `self.Layer1(x) + self.Layer2(x)` 的形式的计算来替换 `z₀ = self.Layer1(x, w)` 形式的计算。
* 如果做得正确，得到的函数 `f(xᵢ, hᵢ) = g(zᵢ) = g(z_xi, hᵢ)` 在 **x** 和 **h** 上都是非线性的。
* 隐藏层大小 `d` 应该足够大。
* 从一个浅层的网络 `f` 开始，并找出隐藏层大小和学习率的良好值，然后再使网络更深。如果你一开始就用一个深层网络，你将有指数级更多的超参数组合，搞错任何一个超参数都可能导致你的性能急剧下降。

#### 你的任务
完成 `models.py` 中 `LanguageIDModel` 类、`train.py` 中 `train_langaugeid` 方法以及 `losses.py` 中 `languageid_loss` 方法的实现。

为了在这个问题上获得满分，你的架构应该能够在测试集上达到至少81%的准确率。

要测试你的实现，请运行自动评分器：
```bash
python autograder.py -q q4
```
**免责声明：** 这个数据集是使用自动文本处理生成的，可能包含错误。它也没有经过不当言论的过滤。然而，尽管数据存在局限性，我们的参考实现仍然可以正确分类超过89%的验证集。我们的参考实现需要10-20个周期来训练。

---

### 问题 5 (3分): 卷积神经网络

通常在训练神经网络时，有必要使用比你一直在使用的简单线性层更高级的层。一种常见的层类型是卷积层。卷积层在训练多维输入时，可以更容易地考虑空间信息。例如，考虑以下输入：

[**图片描述：** 一个d x n的输入矩阵 Input]

如果我们使用一个线性层，类似于问题2中的做法，为了将这个输入送入你的神经网络，你将不得不将其展平成以下形式：
`Input = [x₁₁, x₁₂, x₁₃ ... x₁ₙ ... x_dn]`

但在某些问题中，比如图像分类，如果你看的是原始的二维形式，识别图像是什么就容易得多。这就是卷积层发挥作用的地方。

与其让权重是一个一维向量，一个2D卷积层会将权重存储为一个2D矩阵：

[**图片描述：** 一个2x2的权重矩阵 Weights]

当给定一些输入时，该层然后将输入矩阵与输出矩阵进行卷积。完成这个操作后，一个卷积神经网络可以将卷积层的输出变成一维，并通过线性层传递，然后返回最终输出。

一个2D卷积可以定义如下：

[**图片描述：** 一个d x n的输出矩阵 Output]

其中 `aᵢⱼ` 是通过对权重矩阵和输入矩阵中从 `xᵢⱼ` 开始且与权重矩阵具有相同宽度和高度的部分进行逐元素乘法来创建的。然后我们取结果矩阵的和来计算 `aᵢⱼ`。例如，如果我们想找到 `a₂₂`，我们会将权重乘以以下矩阵：

[**图片描述：** 一个2x2的输入子矩阵]

得到：

[**图片描述：** 元素乘法后的2x2矩阵]

在取这个矩阵的和之前：`a₂₂ = x₂₂*w₁₁ + x₂₃*w₁₂ + x₃₂*w₂₁ + x₃₃*w₂₂`

有时在应用卷积时，输入矩阵会用0进行填充，以确保输出和输入矩阵可以具有相同的大小。然而，在这个问题中，这是不需要的。因此，你的输出矩阵应该比你的输入矩阵小。

你的任务是首先填写 `models.py` 中的 `Convolve` 函数。这个函数接受一个输入矩阵和一个权重矩阵，并对两者进行卷积。注意，可以保证输入矩阵总是比权重矩阵大，并且总是会一次性传入一个，所以你不需要确保你的函数可以同时卷积多个输入。

完成这个之后，完成 `models.py` 中的 `DigitConvolutionalModel()` 类，`train.py` 中的 `train_digitconvolution` 方法，以及 `losses.py` 中的 `digitconvolution_loss`。你可以重用你在问题3中的大部分代码。

自动评分器将首先检查你的 `convolve` 函数，以确保它正确地计算了两个矩阵的卷积。然后它将测试你的模型，看它是否能在 MNIST 数据集的一个大大简化的子集上达到80%的准确率。由于这个问题主要关注你将要编写的 `Convolve()` 函数，你的模型应该训练得相对较快。

在这个问题中，你的卷积网络可能会运行得有点慢，这是预期的，因为像 Pytorch 这样的包有它们用来加速卷积的优化。然而，这不应该影响你的最终分数，因为我们为你提供了一个更容易的 MNIST 数据集版本来训练。

**模型提示：** 我们已经为你实现了卷积层并将其展平。你现在可以将展平的矩阵当作一个常规的一维输入，通过线性层传递。你只需要几个小的层就能达到80%的准确率。

---

### 问题 6 (2分): 注意力机制 (Attention)

注意力机制是机器学习中一个相对较新的概念，用于自然语言处理等任务，理论上帮助神经网络学习优先处理一段文本的重要部分。在这个问题中，我们将实现一种称为“缩放点积注意力”（Scaled Dot-Product Attention）的注意力机制，它由以下公式给出：

![注意力公式](https://latex.codecogs.com/svg.image?softmax(M\frac{(Q)(K)^T}{\sqrt{d_k}})(V))

这里，`Q`, `K`, `V` 都是输入矩阵，不一定是向量。在我们的例子中，我们将让 `Q`, `K`, 和 `V` 都等于应用了线性层的输入矩阵，原因将在下一个问题中看到。pytorch函数 `matmul` 将必须用于将它们相乘。此外，`dₖ` 是正在使用的层大小。最后，符号 `Aᵀ` 用于表示取矩阵的转置。这可以通过使用 `movedim` 交换矩阵的第2和第3维来完成，就像在问题4中做的那样。

此外，你将对你的注意力层应用一个掩码（由 `M` 表示）。掩码是一个布尔矩阵，它控制我们的神经网络可以查看我们输入中的哪些元素。在这种情况下，我们想实现一个因果掩码，它防止神经网络在处理字符序列时“向前看”未来的项。关于如何做到这一点的更多信息可以在骨架代码中找到。

获得问题6分数的唯一任务是填写 `models.py` 中的 `AttentionBlock` 类。问题7是可选的，将引导你在生成式神经网络中使用它。

---

### 问题 7 (0分，但很有趣): 字符级GPT (character-GPT)

这个问题是 Andrej Karpathy 的 “minGPT” 的修改版本，如果你想玩一个更复杂、更强大的模型版本，这是一个很好的资源。

现在你已经构建了一个注意力块，你可以转向一种在过去几年中变得非常流行的架构类型：Transformers。一些更广泛使用的基于transformer的模型，包括GPT，都专注于文本生成。

你将构建一个生成模型的小得多的版本，它将在莎士比亚戏剧的大量样本上进行训练（在这里下载它们并将它们放在你的项目文件夹中）。为了使它可以在CPU上进行训练，这个模型将生成序列中的下一个字符而不是下一个词。你需要编辑的所有代码都位于 `gpt_model.py` 中。

GPT的一般结构如下所示：

[**图片描述：** 一个GPT模型的通用结构图。它由文本和位置嵌入层开始，然后是12个Transformer块（包含多头自注意力、前馈网络和层归一化），最后是文本预测和任务分类的输出层。]

中间的蓝色矩形代表一个单一的transformer块。它由以下步骤组成：
1. 调用你的注意力块
2. 将步骤1的输出和transformer块的输入相加
3. 对步骤2的输出进行归一化
4. 应用一个后跟relu激活的单线性层
5. 将步骤3和4的输出相加
6. 对步骤5的输出进行归一化

你应该在 `Transformer_Block` 类的 `forward` 函数中实现这一点。你需要的所有层都已经在 `__init__` 中初始化了。

这个问题的第二部分是在GPT的 `forward` 函数中组装整个架构。以上图为粗略指南，第一步是创建一个“嵌入层”。为了本项目的目的，你可以认为它本质上是一个线性层，这个层以及所有其他层都已经在 `__init__()` 函数中为你初始化了。接下来，你将需要在输入上应用一系列的transformer块。虽然上图使用了12个，但由于你将使用一个较小的数据集，你将不需要那么多。最后，你将应用一个归一化层，然后是最后一个线性层，然后返回输出。

注意，这最后一层不应该有激活函数。最后一层返回下一个字符是任何特定字母的可能性，所以它的行为应该类似于你之前做过的分类问题中的最终层。

要训练这个模型，请运行命令：
```bash
python chargpt.py
```

**下一步：** 由于这个问题不会被评分，我们鼓励你尝试增加网络的大小，用你想要处理的不同文本文件替换 `input.txt`，或者研究使用更大的块大小，关于你可以更改的变量的更多信息可以在文件 `chargpt.py` 中找到。你也可以看看“minGPT”，以获得一个更强大的版本来玩。

---

### 提交

为了提交你的项目，请上传你编辑过的 Python 文件。例如，使用 Gradescope 上传项目文件夹中所有的 `.py` 文件。

完整的项目自动评分器在标准参考解决方案下大约需要 **12分钟** 运行。如果你的代码花费的时间明显更长，请考虑检查你的实现效率。

如果你与一个伙伴合作，只有一个伙伴应该提交代码，并在 Gradescope 上**标记另一个伙伴**。不要提交两份相同的代码；你可能会因此被错误地标记为学术不端行为。
